{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c61eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464f8acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Stavan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Stavan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Stavan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "579744d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bbc-text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db9283b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2af526ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b1d8f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                               text\n",
       "0     tech  tv future in the hands of viewers with home th..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c525caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'worldcom boss  left books alone  former worldcom boss bernie ebbers  who is accused of overseeing an $11bn (Â£5.8bn) fraud  never made accounting decisions  a witness has told jurors.  david myers made the comments under questioning by defence lawyers who have been arguing that mr ebbers was not responsible for worldcom s problems. the phone company collapsed in 2002 and prosecutors claim that losses were hidden to protect the firm s shares. mr myers has already pleaded guilty to fraud and is assisting prosecutors.  on monday  defence lawyer reid weingarten tried to distance his client from the allegations. during cross examination  he asked mr myers if he ever knew mr ebbers  make an accounting decision  .  not that i am aware of   mr myers replied.  did you ever know mr ebbers to make an accounting entry into worldcom books   mr weingarten pressed.  no   replied the witness. mr myers has admitted that he ordered false accounting entries at the request of former worldcom chief financial officer scott sullivan. defence lawyers have been trying to paint mr sullivan  who has admitted fraud and will testify later in the trial  as the mastermind behind worldcom s accounting house of cards.  mr ebbers  team  meanwhile  are looking to portray him as an affable boss  who by his own admission is more pe graduate than economist. whatever his abilities  mr ebbers transformed worldcom from a relative unknown into a $160bn telecoms giant and investor darling of the late 1990s. worldcom s problems mounted  however  as competition increased and the telecoms boom petered out. when the firm finally collapsed  shareholders lost about $180bn and 20 000 workers lost their jobs. mr ebbers  trial is expected to last two months and if found guilty the former ceo faces a substantial jail sentence. he has firmly declared his innocence.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52f35f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = df['text']\n",
    "labels = df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82d188c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels.hist(figsize=(10,5))#The point of this is to see whether or not we have imbalanced classes.That is if any class is over \n",
    "# or under represented. This can be an issue when we check our model's performance since, for example, if ninety nine percent\n",
    "#of our data belongs to one class, we can obtain ninety nine percent accuracy by only predicting that. In that case,\n",
    "#we would want to use other metrics in order to get a better sense of how our model is"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3492bab7",
   "metadata": {},
   "source": [
    "So notice that our labels seem to be pretty evenly spread out because of this, we can say that our data is not imbalanced. And so there isn't a great need to check alternative metrics. Also, this gives us a chance to see what labels were working with notice that we have five labels business,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc910dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next step is to do a train test, split note that we do this before using the Count Vectorizer.\n",
    "inputs_train, inputs_test, Y_train, Y_test = train_test_split(inputs, labels, random_state= 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "615e2173",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer() # we are not using any arguments here, simply initiating the CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eda085d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(inputs_train)\n",
    "X_test = vectorizer.transform(inputs_test)\n",
    "# why we call fit transform in one case, but only transform in the other case.. Recall that the training data is supposed \n",
    "# to represent what we have when we build our model. The test data is supposed to represent what we have when we apply our\n",
    "# model to data we haven't seen before. As such, we would not want to fit on the test data because that's not how test data \n",
    "# will be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b238b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1668x25997 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 336528 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n",
    "# X train and X tests are matrices with number of rows equal to the number of data samples and number of columns equal \n",
    "# to the vocabulary size."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f92f7d80",
   "metadata": {},
   "source": [
    "the reason these special types of matrices are used is because most of the values in the Matrix are zero. That is, most documents do not make use of most words. Using a sparse matrix representation is more efficient. Also note the size of this matrix we have about six hundred rows and about 26000 columns. Note that this is typically very undesirable in machine learning. Note that this is typically very undesirable in machine learning. This is not necessarily a detriment in this particular case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0b4ad96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336528"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b217c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007760718378407248"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % of values that are non-zero \n",
    "(X_train != 0).sum() / np.prod(X_train.shape)#On the denominator, we have the product of extreme dot shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "263f49ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score : 0.9928057553956835\n",
      "test score : 0.9766606822262118\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, Y_train)\n",
    "print('train score :', model.score(X_train, Y_train))\n",
    "print('test score :', model.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a61a852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score : 0.9940047961630696\n",
      "test score : 0.9730700179533214\n"
     ]
    }
   ],
   "source": [
    "#with Stop words\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train = vectorizer.fit_transform(inputs_train)\n",
    "X_test = vectorizer.transform(inputs_test)\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, Y_train)\n",
    "print('train score :', model.score(X_train, Y_train))\n",
    "print('test score :', model.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97ff6606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will map parts of speech tags in NLTK\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else :\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92f95e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is going to do all the work of tokenizing and limiting each document. \n",
    "# What do we want to do is create an object and then we want to be able to call that object as if it were afunction\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        tokens = word_tokenize(doc)  #like string.split\n",
    "        words_tags = nltk.pos_tag(tokens)\n",
    "        return [self.wnl.lemmatize(word, pos= get_wordnet_pos(tag)) for word, tag in words_tags]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bbdd5fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score : 0.9946043165467626\n",
      "test score : 0.9730700179533214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1668, 25024)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with Lemmatization  -- very slow process - time consuming\n",
    "vectorizer = CountVectorizer(tokenizer=LemmaTokenizer())#Note that this takes in any callable, so an object with a call function is acceptable.\n",
    "X_train = vectorizer.fit_transform(inputs_train)\n",
    "X_test = vectorizer.transform(inputs_test)\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, Y_train)\n",
    "print('train score :', model.score(X_train, Y_train))\n",
    "print('test score :', model.score(X_test, Y_test))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "790e09b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemTokenizer:\n",
    "    def __init__(self):\n",
    "        self.porter = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        tokens = word_tokenize(doc)  #like string.split\n",
    "        return [self.porter.stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6793ae7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score : 0.9922062350119905\n",
      "test score : 0.9748653500897666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1668, 21901)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with Stemming\n",
    "vectorizer = CountVectorizer(tokenizer=StemTokenizer())#Note that this takes in any callable, so an object with a call function is acceptable.\n",
    "X_train = vectorizer.fit_transform(inputs_train)\n",
    "X_test = vectorizer.transform(inputs_test)\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, Y_train)\n",
    "print('train score :', model.score(X_train, Y_train))\n",
    "print('test score :', model.score(X_test, Y_test))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3f5b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenizer(s):\n",
    "    return s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07a42df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score : 0.9934052757793765\n",
      "test score : 0.9694793536804309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1668, 37787)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with split tokenizer\n",
    "vectorizer = CountVectorizer(tokenizer=simple_tokenizer)#Note that this takes in any callable, so an object with a call function is acceptable.\n",
    "X_train = vectorizer.fit_transform(inputs_train)\n",
    "X_test = vectorizer.transform(inputs_test)\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, Y_train)\n",
    "print('train score :', model.score(X_train, Y_train))\n",
    "print('test score :', model.score(X_test, Y_test))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a70ec94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now when we see the shape of X-train for each case, we can see how the dimensionality is reduced with stemming and lemmatization\n",
    "# and also in this case stemming performed better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765e061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
