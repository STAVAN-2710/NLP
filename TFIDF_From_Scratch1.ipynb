{"cells":[{"cell_type":"code","execution_count":null,"id":"c8a0ee74","metadata":{"id":"c8a0ee74"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import nltk\n","\n","from nltk import word_tokenize"]},{"cell_type":"code","execution_count":null,"id":"73632808","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"73632808","executionInfo":{"status":"ok","timestamp":1660821781444,"user_tz":-330,"elapsed":708,"user":{"displayName":"STAVAN SANYAL","userId":"09124032418210120991"}},"outputId":"2429f538-186b-4226-9329-6c0bd479a2a1"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}],"source":["nltk.download('punkt')"]},{"cell_type":"code","execution_count":null,"id":"242caa88","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":345},"id":"242caa88","executionInfo":{"status":"error","timestamp":1660821783366,"user_tz":-330,"elapsed":6,"user":{"displayName":"STAVAN SANYAL","userId":"09124032418210120991"}},"outputId":"5717985c-00cb-40b3-dec5-9be0e292eb7d"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-1dba1b481b31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmovies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C:/Users/Stavan/Documents/PYTHON/DATA SCIENCE PROJECTS/MOVIE RECOMMENDER/tmdb_5000_movies.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmovies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bbc-text.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# movies.head()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Stavan/Documents/PYTHON/DATA SCIENCE PROJECTS/MOVIE RECOMMENDER/tmdb_5000_movies.csv'"]}],"source":["movies = pd.read_csv('C:/Users/Stavan/Documents/PYTHON/DATA SCIENCE PROJECTS/MOVIE RECOMMENDER/tmdb_5000_movies.csv')\n","movies = pd.read_csv('bbc-text.csv')\n","# movies.head()"]},{"cell_type":"code","execution_count":null,"id":"074dd9e8","metadata":{"id":"074dd9e8"},"outputs":[],"source":["credits = pd.read_csv('C:/Users/Stavan/Documents/PYTHON/DATA SCIENCE PROJECTS/MOVIE RECOMMENDER/tmdb_5000_credits.csv')"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wRgnt50nsV6i","executionInfo":{"status":"ok","timestamp":1660821821607,"user_tz":-330,"elapsed":24434,"user":{"displayName":"STAVAN SANYAL","userId":"09124032418210120991"}},"outputId":"448c8ee7-14bc-47d8-b652-ff42171f7028"},"id":"wRgnt50nsV6i","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"id":"0f11bdb0","metadata":{"id":"0f11bdb0","outputId":"1215e6ff-e1df-45ab-d146-20751adb153a"},"outputs":[{"data":{"text/plain":["(2225, 2)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# movies['overview'].to_string() \n","# for i in movies['overview']:\n","#     print(i.types())\n","    \n","movies.dropna(inplace=True)\n","movies.shape"]},{"cell_type":"code","execution_count":null,"id":"4ec13f06","metadata":{"id":"4ec13f06","outputId":"421e676c-668e-4e80-d206-d185dbd8e3ff"},"outputs":[{"name":"stderr","output_type":"stream","text":["IOPub data rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_data_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n"]}],"source":["# word_to_index\n","# convert documents to series of ints/ids/indices\n","idx = 0\n","word2idx = {}\n","tokenized_docs = []\n","doc_as_int = []\n","for doc in movies['text'] :\n","    words = word_tokenize(doc.lower())\n","    doc_as_int = []\n","    for word in words:\n","        if word not in word2idx:\n","            word2idx[word] = idx\n","            idx += 1\n","#             for later\n","        doc_as_int.append(word2idx[word])\n","    tokenized_docs.append(doc_as_int)\n","    \n","print(tokenized_docs)"]},{"cell_type":"code","execution_count":null,"id":"e541ef70","metadata":{"id":"e541ef70"},"outputs":[],"source":["#reverse mapping\n","# idx2word = {v:k for k, v in word2idx.items()} #this is for set representation\n","# this is somewhat inefficient because we're using a dictionary data structure, even though our \n","# indices are only integers from zero up to the vocabulary size.It would be more efficient to store a list instead.\n","idx2word = []\n","for k, v in word2idx.items():\n","    idx2word.insert(v, k)"]},{"cell_type":"code","execution_count":null,"id":"4dc2c25d","metadata":{"scrolled":true,"id":"4dc2c25d","outputId":"60a5feb8-c2f4-43cf-d1a1-56eae29828dd"},"outputs":[{"data":{"text/plain":["['tv',\n"," 'future',\n"," 'in',\n"," 'the',\n"," 'hands',\n"," 'of',\n"," 'viewers',\n"," 'with',\n"," 'home',\n"," 'theatre',\n"," 'systems',\n"," 'plasma',\n"," 'high-definition',\n"," 'tvs',\n"," 'and',\n"," 'digital',\n"," 'video',\n"," 'recorders',\n"," 'moving',\n"," 'into',\n"," 'living',\n"," 'room',\n"," 'way',\n"," 'people',\n"," 'watch',\n"," 'will',\n"," 'be',\n"," 'radically',\n"," 'different',\n"," 'five',\n"," 'years',\n"," 'time',\n"," '.',\n"," 'that',\n"," 'is',\n"," 'according',\n"," 'to',\n"," 'an',\n"," 'expert',\n"," 'panel',\n"," 'which',\n"," 'gathered',\n"," 'at',\n"," 'annual',\n"," 'consumer',\n"," 'electronics',\n"," 'show',\n"," 'las',\n"," 'vegas',\n"," 'discuss',\n"," 'how',\n"," 'these',\n"," 'new',\n"," 'technologies',\n"," 'impact',\n"," 'one',\n"," 'our',\n"," 'favourite',\n"," 'pastimes',\n"," 'us',\n"," 'leading',\n"," 'trend',\n"," 'programmes',\n"," 'other',\n"," 'content',\n"," 'delivered',\n"," 'via',\n"," 'networks',\n"," 'through',\n"," 'cable',\n"," 'satellite',\n"," 'telecoms',\n"," 'companies',\n"," 'broadband',\n"," 'service',\n"," 'providers',\n"," 'front',\n"," 'rooms',\n"," 'portable',\n"," 'devices',\n"," 'most',\n"," 'talked-about',\n"," 'ces',\n"," 'has',\n"," 'been',\n"," 'personal',\n"," '(',\n"," 'dvr',\n"," 'pvr',\n"," ')',\n"," 'set-top',\n"," 'boxes',\n"," 'like',\n"," 's',\n"," 'tivo',\n"," 'uk',\n"," 'sky+',\n"," 'system',\n"," 'allow',\n"," 'record',\n"," 'store',\n"," 'play',\n"," 'pause',\n"," 'forward',\n"," 'wind',\n"," 'when',\n"," 'they',\n"," 'want',\n"," 'essentially',\n"," 'technology',\n"," 'allows',\n"," 'for',\n"," 'much',\n"," 'more',\n"," 'personalised',\n"," 'are',\n"," 'also',\n"," 'being',\n"," 'built-in',\n"," 'sets',\n"," 'big',\n"," 'business',\n"," 'japan',\n"," 'but',\n"," 'slower',\n"," 'take',\n"," 'off',\n"," 'europe',\n"," 'because',\n"," 'lack',\n"," 'programming',\n"," 'not',\n"," 'only',\n"," 'can',\n"," 'adverts',\n"," 'forget',\n"," 'about',\n"," 'abiding',\n"," 'by',\n"," 'network',\n"," 'channel',\n"," 'schedules',\n"," 'putting',\n"," 'together',\n"," 'their',\n"," 'own',\n"," 'a-la-carte',\n"," 'entertainment',\n"," 'some',\n"," 'worried',\n"," 'what',\n"," 'it',\n"," 'means',\n"," 'them',\n"," 'terms',\n"," 'advertising',\n"," 'revenues',\n"," 'as',\n"," 'well',\n"," 'brand',\n"," 'identity',\n"," 'viewer',\n"," 'loyalty',\n"," 'channels',\n"," 'although',\n"," 'leads',\n"," 'this',\n"," 'moment',\n"," 'a',\n"," 'concern',\n"," 'raised',\n"," 'particularly',\n"," 'growing',\n"," 'uptake',\n"," 'services',\n"," 'happens',\n"," 'here',\n"," 'today',\n"," 'we',\n"," 'see',\n"," 'nine',\n"," 'months',\n"," 'adam',\n"," 'hume',\n"," 'bbc',\n"," 'broadcast',\n"," 'futurologist',\n"," 'told',\n"," 'news',\n"," 'website',\n"," 'likes',\n"," 'there',\n"," 'no',\n"," 'issues',\n"," 'lost',\n"," 'revenue',\n"," 'yet',\n"," 'pressing',\n"," 'issue',\n"," 'commercial',\n"," 'broadcasters',\n"," 'important',\n"," 'everyone',\n"," 'talking',\n"," 'brands',\n"," 'rather',\n"," 'than',\n"," 'said',\n"," 'tim',\n"," 'hanlon',\n"," 'from',\n"," 'communications',\n"," 'firm',\n"," 'starcom',\n"," 'mediavest',\n"," 'reality',\n"," 'connections',\n"," 'anybody',\n"," 'producer',\n"," 'he',\n"," 'added',\n"," ':',\n"," 'challenge',\n"," 'now',\n"," 'hard',\n"," 'promote',\n"," 'programme',\n"," 'so',\n"," 'choice',\n"," 'stacey',\n"," 'jolna',\n"," 'senior',\n"," 'vice',\n"," 'president',\n"," 'guide',\n"," 'group',\n"," 'find',\n"," 'simplified',\n"," 'or',\n"," 'could',\n"," 'leaf',\n"," 'out',\n"," 'google',\n"," 'book',\n"," 'search',\n"," 'engine',\n"," 'instead',\n"," 'scheduler',\n"," 'help',\n"," 'kind',\n"," 'model',\n"," 'might',\n"," 'work',\n"," 'younger',\n"," 'ipod',\n"," 'generation',\n"," 'used',\n"," 'taking',\n"," 'control',\n"," 'gadgets',\n"," 'on',\n"," 'suit',\n"," 'recognised',\n"," 'older',\n"," 'generations',\n"," 'comfortable',\n"," 'familiar',\n"," 'know',\n"," 'getting',\n"," 'perhaps',\n"," 'do',\n"," 'put',\n"," 'mr',\n"," 'suggested',\n"," 'end',\n"," 'you',\n"," 'have',\n"," 'kids',\n"," 'just',\n"," 'diapers',\n"," 'who',\n"," 'pushing',\n"," 'buttons',\n"," 'already',\n"," '-',\n"," 'everything',\n"," 'possible',\n"," 'available',\n"," 'ultimately',\n"," 'tell',\n"," 'market',\n"," '50',\n"," '000',\n"," 'showcased',\n"," 'many',\n"," 'enhancing',\n"," 'tv-watching',\n"," 'experience',\n"," 'everywhere',\n"," 'models',\n"," 'lcd',\n"," 'liquid',\n"," 'crystal',\n"," 'display',\n"," 'launched',\n"," 'capability',\n"," 'built',\n"," 'external',\n"," 'such',\n"," 'example',\n"," 'humax',\n"," '26-inch',\n"," '80-hour',\n"," 'dvd',\n"," 'recorder',\n"," 'biggest',\n"," 'directtv',\n"," 'even',\n"," 'its',\n"," 'branded',\n"," '100-hours',\n"," 'recording',\n"," 'instant',\n"," 'replay',\n"," 'function',\n"," 'set',\n"," 'rewind',\n"," 'up',\n"," '90',\n"," 'hours',\n"," 'microsoft',\n"," 'chief',\n"," 'bill',\n"," 'gates',\n"," 'announced',\n"," 'his',\n"," 'pre-show',\n"," 'keynote',\n"," 'speech',\n"," 'partnership',\n"," 'called',\n"," 'tivotogo',\n"," 'recorded',\n"," 'windows',\n"," 'pcs',\n"," 'mobile',\n"," 'all',\n"," 'reflect',\n"," 'increasing',\n"," 'freeing',\n"," 'multimedia',\n"," 'worldcom',\n"," 'boss',\n"," 'left',\n"," 'books',\n"," 'alone',\n"," 'former',\n"," 'bernie',\n"," 'ebbers',\n"," 'accused',\n"," 'overseeing',\n"," '$',\n"," '11bn',\n"," '£5.8bn',\n"," 'fraud',\n"," 'never',\n"," 'made',\n"," 'accounting',\n"," 'decisions',\n"," 'witness',\n"," 'jurors',\n"," 'david',\n"," 'myers',\n"," 'comments',\n"," 'under',\n"," 'questioning',\n"," 'defence',\n"," 'lawyers',\n"," 'arguing',\n"," 'was',\n"," 'responsible',\n"," 'problems',\n"," 'phone',\n"," 'company',\n"," 'collapsed',\n"," '2002',\n"," 'prosecutors',\n"," 'claim',\n"," 'losses',\n"," 'were',\n"," 'hidden',\n"," 'protect',\n"," 'shares',\n"," 'pleaded',\n"," 'guilty',\n"," 'assisting',\n"," 'monday',\n"," 'lawyer',\n"," 'reid',\n"," 'weingarten',\n"," 'tried',\n"," 'distance',\n"," 'client',\n"," 'allegations',\n"," 'during',\n"," 'cross',\n"," 'examination',\n"," 'asked',\n"," 'if',\n"," 'ever',\n"," 'knew',\n"," 'make',\n"," 'decision',\n"," 'i',\n"," 'am',\n"," 'aware',\n"," 'replied',\n"," 'did',\n"," 'entry',\n"," 'pressed',\n"," 'admitted',\n"," 'ordered',\n"," 'false',\n"," 'entries',\n"," 'request',\n"," 'financial',\n"," 'officer',\n"," 'scott',\n"," 'sullivan',\n"," 'trying',\n"," 'paint',\n"," 'testify',\n"," 'later',\n"," 'trial',\n"," 'mastermind',\n"," 'behind',\n"," 'house',\n"," 'cards',\n"," 'team',\n"," 'meanwhile',\n"," 'looking',\n"," 'portray',\n"," 'him',\n"," 'affable',\n"," 'admission',\n"," 'pe',\n"," 'graduate',\n"," 'economist',\n"," 'whatever',\n"," 'abilities',\n"," 'transformed',\n"," 'relative',\n"," 'unknown',\n"," '160bn',\n"," 'giant',\n"," 'investor',\n"," 'darling',\n"," 'late',\n"," '1990s',\n"," 'mounted',\n"," 'however',\n"," 'competition',\n"," 'increased',\n"," 'boom',\n"," 'petered',\n"," 'finally',\n"," 'shareholders',\n"," '180bn',\n"," '20',\n"," 'workers',\n"," 'jobs',\n"," 'expected',\n"," 'last',\n"," 'two',\n"," 'found',\n"," 'ceo',\n"," 'faces',\n"," 'substantial',\n"," 'jail',\n"," 'sentence',\n"," 'firmly',\n"," 'declared',\n"," 'innocence',\n"," 'tigers',\n"," 'wary',\n"," 'farrell',\n"," 'gamble',\n"," 'leicester',\n"," 'say',\n"," 'rushed',\n"," 'making',\n"," 'bid',\n"," 'andy',\n"," 'should',\n"," 'great',\n"," 'britain',\n"," 'rugby',\n"," 'league',\n"," 'captain',\n"," 'decide',\n"," 'switch',\n"," 'codes',\n"," 'else',\n"," 'involved',\n"," 'process',\n"," 'still',\n"," 'away',\n"," 'going',\n"," 'next',\n"," 'stage',\n"," 'john',\n"," 'wells',\n"," 'radio',\n"," 'lot',\n"," 'unknowns',\n"," 'least',\n"," 'medical',\n"," 'situation',\n"," 'whoever',\n"," 'does',\n"," 'had',\n"," 'persistent',\n"," 'knee',\n"," 'operation',\n"," 'weeks',\n"," 'ago',\n"," 'another',\n"," 'three',\n"," 'saracens',\n"," 'believed',\n"," 'head',\n"," 'list',\n"," 'union',\n"," 'clubs',\n"," 'interested',\n"," 'signing',\n"," 'decides',\n"," 'move',\n"," '15-man',\n"," 'game',\n"," 'across',\n"," 'believes',\n"," 'would',\n"," 'better',\n"," 'playing',\n"," 'backs',\n"," 'initially',\n"," 'm',\n"," 'sure',\n"," 'step',\n"," 'between',\n"," 'centre',\n"," 'think',\n"," 'england',\n"," 'prefer',\n"," 'progress',\n"," 'position',\n"," 'back',\n"," 'row',\n"," 'where',\n"," 'use',\n"," 'skills',\n"," 'within',\n"," 'forwards',\n"," 'jury',\n"," 'whether',\n"," 'divide',\n"," 'club',\n"," 'balance',\n"," 'struck',\n"," 'cost',\n"," 'option',\n"," 'bringing',\n"," 'ready-made',\n"," 'replacement',\n"," 'yeading',\n"," 'face',\n"," 'newcastle',\n"," 'fa',\n"," 'cup',\n"," 'premiership',\n"," 'side',\n"," 'united',\n"," 'trip',\n"," 'ryman',\n"," 'premier',\n"," 'leaders',\n"," 'third',\n"," 'round',\n"," 'arguably',\n"," 'highlight',\n"," 'draw',\n"," 'potential',\n"," 'money-spinner',\n"," 'non-league',\n"," 'beat',\n"," 'slough',\n"," 'second',\n"," 'conference',\n"," 'exeter',\n"," 'city',\n"," 'knocked',\n"," 'doncaster',\n"," 'saturday',\n"," 'travel',\n"," 'old',\n"," 'trafford',\n"," 'meet',\n"," 'holders',\n"," 'manchester',\n"," 'january',\n"," 'arsenal',\n"," 'drawn',\n"," 'stoke',\n"," 'chelsea',\n"," 'host',\n"," 'scunthorpe',\n"," 'hinckley',\n"," 'held',\n"," 'brentford',\n"," 'goalless',\n"," 'sunday',\n"," 'luton',\n"," 'win',\n"," 'against',\n"," 'martin',\n"," 'allen',\n"," 'griffin',\n"," 'park',\n"," 'number',\n"," 'teams',\n"," 'difficult',\n"," 'games',\n"," 'championship',\n"," 'sides',\n"," 'weekend',\n"," '8/9',\n"," 'third-placed',\n"," 'everton',\n"," 'visit',\n"," 'plymouth',\n"," 'liverpool',\n"," 'burnley',\n"," 'palace',\n"," 'go',\n"," 'sunderland',\n"," 'fulham',\n"," 'carling',\n"," 'semi-finalists',\n"," 'watford',\n"," 'bolton',\n"," 'ipswich',\n"," 'while',\n"," 'aston',\n"," 'villa',\n"," 'sheffield',\n"," 'strugglers',\n"," 'norwich',\n"," 'blackburn',\n"," 'west',\n"," 'brom',\n"," 'ham',\n"," 'cardiff',\n"," 'preston',\n"," 'north',\n"," 'respectively',\n"," 'southampton',\n"," 'northampton',\n"," 'having',\n"," 'beaten',\n"," 'earlier',\n"," 'season',\n"," 'middlesbrough',\n"," 'either',\n"," 'swindon',\n"," 'notts',\n"," 'county',\n"," 'spurs',\n"," 'entertain',\n"," 'brighton',\n"," 'white',\n"," 'hart',\n"," 'lane',\n"," 'v',\n"," 'swindon/notts',\n"," 'co',\n"," 'man',\n"," 'utd',\n"," 'blackpool',\n"," 'derby',\n"," 'wigan',\n"," 'wolves',\n"," 'millwall',\n"," 'hull',\n"," 'colchester',\n"," 'tottenham',\n"," 'reading',\n"," 'stockport/swansea',\n"," 'birmingham',\n"," 'leeds',\n"," 'hartlepool',\n"," 'boston',\n"," 'milton',\n"," 'keynes',\n"," 'dons',\n"," 'peterborough',\n"," 'oldham',\n"," 'charlton',\n"," 'rochdale',\n"," 'sheff',\n"," 'rotherham',\n"," 'yeovil',\n"," 'bournemouth',\n"," 'chester',\n"," 'coventry',\n"," 'crewe',\n"," 'portsmouth',\n"," 'gillingham',\n"," 'qpr',\n"," 'nottm',\n"," 'forest',\n"," 'hinckley/brentford',\n"," 'matches',\n"," 'played',\n"," 'ocean',\n"," 'twelve',\n"," 'raids',\n"," 'box',\n"," 'office',\n"," 'crime',\n"," 'caper',\n"," 'sequel',\n"," 'starring',\n"," 'george',\n"," 'clooney',\n"," 'brad',\n"," 'pitt',\n"," 'julia',\n"," 'roberts',\n"," 'gone',\n"," 'straight',\n"," 'chart',\n"," 'took',\n"," '40.8m',\n"," '£21m',\n"," 'ticket',\n"," 'sales',\n"," 'studio',\n"," 'estimates',\n"," 'follows',\n"," 'master',\n"," 'criminals',\n"," 'try',\n"," 'pull',\n"," 'major',\n"," 'heists',\n"," 'week',\n"," 'national',\n"," 'treasure',\n"," 'place',\n"," 'wesley',\n"," 'snipes',\n"," 'blade',\n"," 'trinity',\n"," '16.1m',\n"," '£8.4m',\n"," 'rounding',\n"," 'top',\n"," 'animated',\n"," 'fable',\n"," 'polar',\n"," 'express',\n"," 'tom',\n"," 'hanks',\n"," 'festive',\n"," 'comedy',\n"," 'christmas',\n"," 'kranks',\n"," 'triumph',\n"," 'marks',\n"," 'fourth-biggest',\n"," 'opening',\n"," 'december',\n"," 'release',\n"," 'after',\n"," 'films',\n"," 'lord',\n"," 'rings',\n"," 'trilogy',\n"," 'narrowly',\n"," '2001',\n"," 'predecessor',\n"," 'eleven',\n"," '38.1m',\n"," '£19.8m',\n"," '184m',\n"," '£95.8m',\n"," 'total',\n"," 'remake',\n"," '1960s',\n"," 'film',\n"," 'frank',\n"," 'sinatra',\n"," 'rat',\n"," 'pack',\n"," 'directed',\n"," 'oscar-winning',\n"," 'director',\n"," 'steven',\n"," 'soderbergh',\n"," 'returns',\n"," 'direct',\n"," 'hit',\n"," 'reunites',\n"," 'matt',\n"," 'damon',\n"," 'garcia',\n"," 'elliott',\n"," 'gould',\n"," 'catherine',\n"," 'zeta-jones',\n"," 'joins',\n"," 'all-star',\n"," 'cast',\n"," 'fun',\n"," 'good',\n"," 'holiday',\n"," 'movie',\n"," 'dan',\n"," 'fellman',\n"," 'distribution',\n"," 'warner',\n"," 'bros.',\n"," 'critics',\n"," 'less',\n"," 'complimentary',\n"," '110m',\n"," '£57.2m',\n"," 'project',\n"," 'los',\n"," 'angeles',\n"," 'times',\n"," 'labelling',\n"," 'dispiriting',\n"," 'vanity',\n"," 'milder',\n"," 'review',\n"," 'york',\n"," 'dubbed',\n"," 'unabashedly',\n"," 'trivial',\n"," 'howard',\n"," 'hits',\n"," 'mongrel',\n"," 'jibe',\n"," 'michael',\n"," 'peter',\n"," 'hain',\n"," 'tory',\n"," 'leader',\n"," 'acting',\n"," 'attack',\n"," 'shows',\n"," 'labour',\n"," 'rattled',\n"," 'opposition',\n"," 'upbeat',\n"," 'party',\n"," 'spring',\n"," 'campaigning',\n"," 'tactics',\n"," 'proved',\n"," 'tories',\n"," 'hitting',\n"," 'anti-terror',\n"," 'debate',\n"," 'something',\n"," 'tells',\n"," 'me',\n"," 'someone',\n"," 'somewhere',\n"," 'little',\n"," 'bit',\n"," 'commons',\n"," 'four',\n"," 'stance',\n"," 'government',\n"," 'anti-terrorism',\n"," 'legislation',\n"," 'country',\n"," 'risk',\n"," 'then',\n"," 'behaving',\n"," 'sake',\n"," 'anything',\n"," 'cling',\n"," 'costs',\n"," 'far',\n"," 'year',\n"," 'compared',\n"," 'fagin',\n"," 'shylock',\n"," 'flying',\n"," 'pig',\n"," 'morning',\n"," 'don',\n"," 't',\n"," 'environment',\n"," 'secretary',\n"," 'margaret',\n"," 'beckett',\n"," 'rejected',\n"," 'comment',\n"," 'telling',\n"," '4',\n"," 'pm',\n"," 'very',\n"," 'real',\n"," 'duty',\n"," 'get',\n"," 'focus',\n"," 'proposals',\n"," 'examples',\n"," 'seeing',\n"," 'believe',\n"," 'really',\n"," 'poor',\n"," 'judgement',\n"," 'behalf',\n"," 'policies',\n"," 'schools',\n"," 'taxes',\n"," 'immigration',\n"," 'striking',\n"," 'chord',\n"," 'voters',\n"," 'since',\n"," 'beginning',\n"," 'election',\n"," 've',\n"," 'political',\n"," 'weather',\n"," 'denied',\n"," 'politics',\n"," 'raising',\n"," 'case',\n"," 'dixon',\n"," 'whose',\n"," 'cancelled',\n"," 'seven',\n"," 'grabbed',\n"," 'headlines',\n"," 'claims',\n"," 'mrs',\n"," 'human',\n"," 'shield',\n"," 'she',\n"," 'blair',\n"," 'plans',\n"," 'quotas',\n"," 'media',\n"," 'coverage',\n"," 'racist',\n"," 'common',\n"," 'sense',\n"," 'pledged',\n"," 'cleaner',\n"," 'hospitals',\n"," 'school',\n"," 'discipline',\n"," 'promise',\n"," 'rid',\n"," 'correctness',\n"," 'curriculum',\n"," 'give',\n"," 'same',\n"," 'chance',\n"," 'decent',\n"," 'state',\n"," 'education',\n"," 'come',\n"," 'ordinary',\n"," 'family',\n"," 'teenage',\n"," 'applying',\n"," 'cambridge',\n"," 'gordon',\n"," 'brown',\n"," 'love',\n"," 'stressed',\n"," 'commitment',\n"," 'cut',\n"," 'red',\n"," 'tape',\n"," 'increase',\n"," 'basic',\n"," 'pension',\n"," 'line',\n"," 'earnings',\n"," 'finished',\n"," ...]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["idx2word"]},{"cell_type":"code","execution_count":null,"id":"639fe46d","metadata":{"id":"639fe46d","outputId":"68e7f922-137b-4346-def3-3f9c51b488a5"},"outputs":[{"data":{"text/plain":["2225"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# number of documents\n","N = len(movies['text'])\n","N"]},{"cell_type":"code","execution_count":null,"id":"98746c5e","metadata":{"id":"98746c5e","outputId":"0a0b1d88-954f-44ac-f4a1-75888e9ece7b"},"outputs":[{"data":{"text/plain":["33990"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# number of words (vocabulary size)\n","V = len(word2idx)\n","V"]},{"cell_type":"code","execution_count":null,"id":"2c31bcea","metadata":{"id":"2c31bcea","outputId":"ddece96a-e86f-42f3-9b3d-c963435f54b0"},"outputs":[{"data":{"text/plain":["array([[0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.]])"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# instantiate term frequency matrix \n","# although it would be more efficient to use a sparse matrix that makes things a bit more \n","# complicated without improving your understanding.Thus, in this script, we will be using\n","# a dense matrix, which is just a regular Numpy array.\n","# note - could have used count vectorizer\n","\n","tf = np.zeros((N,V))\n","tf"]},{"cell_type":"code","execution_count":null,"id":"fdae7194","metadata":{"id":"fdae7194"},"outputs":[],"source":["for i, doc in enumerate(tokenized_docs):\n","#     print(doc)\n","    for j in doc:\n","        tf[i,j] += 1\n","#         print(j)"]},{"cell_type":"code","execution_count":null,"id":"61927260","metadata":{"id":"61927260","outputId":"1315f023-7cea-4644-a22a-ee05c59336c3"},"outputs":[{"data":{"text/plain":["array([[12.,  2., 12., ...,  0.,  0.,  0.],\n","       [ 0.,  0.,  2., ...,  0.,  0.,  0.],\n","       [ 0.,  0.,  6., ...,  0.,  0.,  0.],\n","       ...,\n","       [ 0.,  0.,  7., ...,  0.,  0.,  0.],\n","       [ 0.,  0., 10., ...,  1.,  1.,  0.],\n","       [ 0.,  1.,  6., ...,  0.,  0.,  1.]])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["tf"]},{"cell_type":"code","execution_count":null,"id":"c8fcd0c9","metadata":{"id":"c8fcd0c9","outputId":"e20139e0-ca84-42e7-8ac7-eead520b8bfc"},"outputs":[{"data":{"text/plain":["array([2.39430622, 2.10539337, 0.00948302, ..., 7.70751219, 7.70751219,\n","       7.70751219])"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["# calculate IDF\n","document_freq = np.sum(tf>0, axis=0) #document_freq shape = (V,)\n","# note that if we call the some function with no arguments, it will just sum up the whole matrix into a single number\n","# And that number will be the number of ones in the whole matrix.Instead, we want to have the sum over each column or \n","# equivalently the sum over each word.Therefore, we must specify axis equals zero.\n","# print(document_freq.shape)\n","idf = np.log(N / document_freq)\n","idf"]},{"cell_type":"code","execution_count":null,"id":"1f1a08f4","metadata":{"id":"1f1a08f4","outputId":"fb5024d2-600d-458a-eea1-ed2790698b94"},"outputs":[{"data":{"text/plain":["array([[2.87316746e+01, 4.21078675e+00, 1.13796292e-01, ...,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n","       [0.00000000e+00, 0.00000000e+00, 1.89660487e-02, ...,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n","       [0.00000000e+00, 0.00000000e+00, 5.68981460e-02, ...,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n","       ...,\n","       [0.00000000e+00, 0.00000000e+00, 6.63811703e-02, ...,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n","       [0.00000000e+00, 0.00000000e+00, 9.48302433e-02, ...,\n","        7.70751219e+00, 7.70751219e+00, 0.00000000e+00],\n","       [0.00000000e+00, 2.10539337e+00, 5.68981460e-02, ...,\n","        0.00000000e+00, 0.00000000e+00, 7.70751219e+00]])"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["# compute tf-idf\n","tf_idf = tf * idf\n","tf_idf"]},{"cell_type":"code","execution_count":null,"id":"9b3a4980","metadata":{"id":"9b3a4980"},"outputs":[],"source":["# random seed so that we get consistent results for the next portion of the notebook\n","np.random.seed(123)"]},{"cell_type":"code","execution_count":null,"id":"6112255e","metadata":{"id":"6112255e","outputId":"58e5333e-1cbb-48f7-bea9-95a4335bc8ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Category: tech\n","Text china  to overtake us net use  the chinese net-using population looks set to exceed that of the us in less than three years  says a report\n","TOP 5 terms:\n","makower\n","net\n","china\n","chinese\n","panlogic\n"]}],"source":["# choose random documents from our dataset and prints out the top five TF IDF terms.\n","# As you recall, our goal is to basically make sure that these makes sense in terms of what we expect tfidf to do\n","i = np.random.choice(N)\n","row = movies.iloc[i]\n","print('Category:', row['category'])\n","print('Text', row['text'].split(\".\",1)[0])\n","print('TOP 5 terms:')\n","\n","scores = tf_idf[i]\n","indices = (-scores).argsort()\n","\n","for j in indices[:5]:\n","    print(idx2word[j])\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"63c6ded4","metadata":{"id":"63c6ded4"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}